# diary_now.py  (Happiness/Sadness/Love/Anger ì „ìš©)
from __future__ import annotations
from pathlib import Path
import csv

# ===== ê²½ë¡œ =====
MODEL_DIR = Path("models/kobert-ml")
BOOKS_CSV = Path("data/items_books.csv")
MOVIES_CSV = Path("data/items_movies.csv")
CUSTOM_LEXICON_CSV = Path("data/custom_lexicon.csv")  # columns: stem,emotion

# ===== ê³ ì • ê°ì •ì…‹ =====
TARGET = ["Happiness", "Sadness", "Love", "Anger"]

# ê³¼ê±°/ì†Œë¬¸ì/ë™ì˜ í‘œí˜„ â†’ í‘œì¤€ ê°ì •ìœ¼ë¡œ ì •ê·œí™”
EMO_MAP = {
    # í‘œì¤€í˜•
    "happiness": "Happiness",
    "sadness": "Sadness",
    "love": "Love",
    "anger": "Anger",
    # ê³¼ê±°/ë™ì˜ ë ˆì´ë¸”
    "joy": "Happiness",
    "happy": "Happiness",
    "sad": "Sadness",
    "mad": "Anger",
    "angry": "Anger",
    # í•œê¸€ ë ˆì´ë¸”ì´ ì„ì—¬ë„ ëŒ€ë¹„
    "ê¸°ì¨": "Happiness",
    "ìŠ¬í””": "Sadness",
    "ì‚¬ë‘": "Love",
    "ë¶„ë…¸": "Anger",
}
def norm_emo(name: str | None) -> str | None:
    if not name: return None
    return EMO_MAP.get(str(name).strip().lower())

# ===== ìµœì†Œ ë‚´ì¥ ì‚¬ì „(ì”¨ì•—) â†’ custom_lexicon.csvì™€ ë³‘í•© ì‚¬ìš© =====
LEXICON_BASE = {
    "Happiness": {"í–‰ë³µ", "ê¸°ì˜", "ì¦ê²", "ì„¤ë ˜", "ìœ ì¾Œ", "í™˜í¬", "í¥ê²¹", "í¥ê²¨"},
    "Sadness": {"ìŠ¬í””", "ìš°ìš¸", "í—ˆì „", "ì¹¨ìš¸", "ëˆˆë¬¼"},
    "Love": {"ì‚¬ë‘", "ì• ì •", "ì¢‹ì•„", "ë‹¤ì •", "ì—°ëª¨", "ì„¤ë ˆ"},
    "Anger": {"í™”ê°€", "ë¶„ë…¸", "ì§œì¦", "ì–µìš¸", "ì„±ë‚¬", "ê²©ë¶„"},
}
NEG = {"ì•ˆ", "ëª»", "ì•„ë‹ˆ", "ë³„ë¡œ", "ëœ", "ë¶€ì •"}  # ë¶€ì • íŠ¸ë¦¬ê±°

# ===== ì „ì²˜ë¦¬/í† í¬ë‚˜ì´ì¦ˆ =====
def ko_tokenize(s: str) -> list[str]:
    try:
        from konlpy.tag import Okt
        okt = Okt()
        return okt.morphs(s, stem=True)
    except Exception:
        # ë§¤ìš° ë‹¨ìˆœ ë°±ì—… í† í¬ë‚˜ì´ì €
        import re
        s = re.sub(r"[\t\r\n.,!?;:\-\(\)\[\]ã€ã€â€œâ€\"'`Â·â€¦]", " ", s)
        return [t for t in s.split() if t]

# ===== ì»¤ìŠ¤í…€ ì‚¬ì „ ë¡œë”© (stem,emotion) =====
def load_custom_lexicon(path: Path = CUSTOM_LEXICON_CSV) -> dict[str, set[str]]:
    if not path.exists():
        return {}
    out: dict[str, set[str]] = {}
    with open(path, "r", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            stem = str(row.get("stem", "")).strip()
            emo_std = norm_emo(row.get("emotion"))
            if stem and emo_std in TARGET:
                out.setdefault(emo_std, set()).add(stem)
    return out

# ===== ì‚¬ì „ ê¸°ë°˜ ìŠ¤ì½”ì–´ =====
def score_fallback(text: str) -> list[tuple[str, float]]:
    # ìµœì‹  ì»¤ìŠ¤í…€ ì‚¬ì „ ë³‘í•©
    merged = {k: set(v) for k, v in LEXICON_BASE.items()}
    custom = load_custom_lexicon()
    for emo, stems in custom.items():
        merged.setdefault(emo, set()).update(stems)

    tokens = ko_tokenize(text)

    # ë¶€ì •ì–´ ì§í›„ window(2) í† í°ì— ë°˜ì „/ê°ì‡„ ì ìš©
    neg_idx: set[int] = set()
    for i, t in enumerate(tokens):
        if any(n in t for n in NEG):
            for j in range(i + 1, min(len(tokens), i + 3)):
                neg_idx.add(j)

    scores = {e: 0.0 for e in TARGET}
    for i, t in enumerate(tokens):
        for emo, stems in merged.items():
            if any(st in t for st in stems):
                scores[emo] += (-0.7 if i in neg_idx else 1.0)

    # ê¸¸ì´ ë³´ì •
    L = max(len(tokens), 1)
    for k in scores:
        scores[k] = round(scores[k] / (L ** 0.5), 4)

    # 1) ì–‘ìˆ˜ ìŠ¤ì½”ì–´ ìš°ì„  ë°˜í™˜
    positives = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    positives = [(e, s) for e, s in positives[:2] if s > 0]
    if positives:
        return positives

    # 2) ëª¨ë‘ ìŒìˆ˜/0ì´ë©´, ê°€ì¥ í° 'ì ˆëŒ€ê°’'ì˜ ìŒìˆ˜ë¥¼ ë§¤í•‘í•´ì„œ ì–‘ìˆ˜ë¡œ í™˜ì‚°
    #    - ë¶€ì •ëœ Happiness/Love -> Sadness ë¡œ í•´ì„(ë³´ìˆ˜ì )
    NEG_MAP = {
        "Happiness": "Sadness",
        "Love": "Sadness",
        "Anger": "Anger",     # "ì•ˆ í™”ë‚¬ì–´"ëŠ” ì‚¬ì‹¤ ì¤‘ë¦½ì— ê°€ê¹ì§€ë§Œ 4ë¼ë²¨ì´ë¼ ë³´ìˆ˜ì ìœ¼ë¡œ ìœ ì§€
        "Sadness": "Sadness",
    }
    negatives = sorted(scores.items(), key=lambda x: abs(x[1]), reverse=True)
    picked: list[tuple[str, float]] = []
    for emo, val in negatives:
        if val < 0:
            mapped = NEG_MAP.get(emo, emo)
            picked.append((mapped, round(abs(val), 4)))
        if len(picked) == 2:
            break
    return picked

# ===== KoBERT ì˜ˆì¸¡ (ìˆìœ¼ë©´ ì‚¬ìš©) =====
def predict_kobert(text: str, threshold=0.5, topk=3):
    if not MODEL_DIR.exists():
        return None
    try:
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        import torch
        tok = AutoTokenizer.from_pretrained(str(MODEL_DIR))
        mdl = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR)).eval()

        t = " ".join(ko_tokenize(text))
        inputs = tok(t, return_tensors="pt", truncation=True, padding=True, max_length=256)
        with torch.no_grad():
            logits = mdl(**inputs).logits
            probs = torch.sigmoid(logits).flatten().tolist()

        id2label = getattr(mdl.config, "id2label", None)
        names_raw = [id2label[i] if id2label else f"label_{i}" for i in range(len(probs))]

        # ëª¨ë¸ ë¼ë²¨ì„ í‘œì¤€ ê°ì •ìœ¼ë¡œ ì •ê·œí™” + ì¤‘ë³µ id ì§‘ê³„
        agg: dict[str, float] = {}
        for n, p in zip(names_raw, probs):
            std = norm_emo(n)
            if std in TARGET:
                agg[std] = max(agg.get(std, 0.0), float(p))  # max(ë˜ëŠ” sum) ì„ íƒ ê°€ëŠ¥

        picked = [(e, agg[e]) for e in agg if agg[e] >= threshold]
        if not picked and agg:
            picked = sorted(agg.items(), key=lambda x: x[1], reverse=True)[:topk]
        return sorted(picked, key=lambda x: x[1], reverse=True)[:2] if picked else None
    except Exception:
        return None

# ===== ì¹´íƒˆë¡œê·¸ ë¡œë“œ ë° ì¶”ì²œ =====
def load_catalog(path: Path):
    if not path.exists(): return None
    items = []
    with open(path, "r", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            # emotions ì»¬ëŸ¼ ìš°ì„ , ì—†ìœ¼ë©´ tagsë„ ê°ì • ëŒ€ìš©ìœ¼ë¡œ ì‹œë„
            emos_raw = [t.strip() for t in str(row.get("emotions", "")).split(";") if t.strip()]
            if not emos_raw:
                emos_raw = [t.strip() for t in str(row.get("tags", "")).split(";") if t.strip()]
            emos_std = []
            for e in emos_raw:
                std = norm_emo(e)
                if std in TARGET:
                    emos_std.append(std)
            row["emotions_std"] = emos_std
            items.append(row)
    return items

def recommend(picked: list[tuple[str, float]], text: str):
    books_cat = load_catalog(BOOKS_CSV)
    movies_cat = load_catalog(MOVIES_CSV)

    if books_cat and movies_cat:
        w = {e: float(p) for e, p in picked}
        toks = set(ko_tokenize(text))

        def score_item(it: dict) -> float:
            emo_score = sum(w.get(e, 0.0) for e in it.get("emotions_std", []))
            tags = [t.strip() for t in str(it.get("tags", "")).split(";") if t.strip()]
            tag_bonus = sum(1 for t in tags if t in toks) * 0.1
            return emo_score + tag_bonus

        books_sorted = sorted(books_cat, key=score_item, reverse=True)[:5]
        movies_sorted = sorted(movies_cat, key=score_item, reverse=True)[:5]
        return books_sorted, movies_sorted, "catalog"

    # ì¹´íƒˆë¡œê·¸ ì—†ìœ¼ë©´ ë‚´ì¥ í´ë°±
    FALLBACK_BOOKS = {
        "Happiness": ["ì•„ì£¼ ì‘ì€ ìŠµê´€ì˜ í˜", "ì–´ë–¤ í•˜ë£¨", "ê±·ëŠ” ì‚¬ëŒ, í•˜ì •ìš°"],
        "Sadness": ["ì•„ëª¬ë“œ", "ì£½ìŒì— ê´€í•˜ì—¬", "ë³´í†µì˜ ì¡´ì¬"],
        "Love": ["ì‚¬ë‘ì˜ ê¸°ìˆ ", "ì—°ì• ì˜ ë¬¸ì¥ë“¤", "ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì "],
        "Anger": ["ê°ì • ì–´íœ˜", "ë©ˆì¶”ë©´, ë¹„ë¡œì†Œ ë³´ì´ëŠ” ê²ƒë“¤", "ì² í•™ì€ ì–´ë–»ê²Œ ì‚¶ì˜ ë¬´ê¸°ê°€ ë˜ëŠ”ê°€"],
    }
    FALLBACK_MOVIES = {
        "Happiness": ["ë¦¬í‹€ í¬ë ˆìŠ¤íŠ¸", "ë¼ë¼ëœë“œ", "ì›”í„°ì˜ ìƒìƒì€ í˜„ì‹¤ì´ ëœë‹¤"],
        "Sadness": ["ë§¨ì²´ìŠ¤í„° ë°”ì´ ë” ì”¨", "ë¬¸ë¼ì´íŠ¸", "ì´í„°ë„ ì„ ìƒ¤ì¸"],
        "Love": ["ë¹„ê¸´ ì–´ê²Œì¸", "ë¹„í¬ ì„ ë¼ì´ì¦ˆ", "ë…¸íŒ… í"],
        "Anger": ["ìœ„í”Œë˜ì‰¬", "ì¡°ì»¤", "ë² í…Œë‘"],
    }

    books, movies = [], []
    for emo, _ in picked:
        books += FALLBACK_BOOKS.get(emo, [])[:3]
        movies += FALLBACK_MOVIES.get(emo, [])[:3]

    def uniq_keep_order(lst: list[str]) -> list[str]:
        seen, out = set(), []
        for x in lst:
            if x not in seen:
                seen.add(x); out.append(x)
        return out

    return [{"title": b} for b in uniq_keep_order(books)[:5]], [{"title": m} for m in uniq_keep_order(movies)[:5]], "fallback"

# ===== ë©”ì¸ =====
if __name__ == "__main__":
    print("ğŸ“ ì—¬ëŸ¬ ì¤„ë¡œ ì¼ê¸°ë¥¼ ì“°ì„¸ìš”. ëë‚´ë ¤ë©´ ë¹ˆ ì¤„ì—ì„œ ì—”í„°.")
    lines: list[str] = []
    while True:
        line = input()
        if not line.strip(): break
        lines.append(line)
    text = "\n".join(lines).strip()
    if not text:
        print("ì…ë ¥ ì—†ìŒ. ì¢…ë£Œ."); raise SystemExit

    picked = predict_kobert(text, threshold=0.5, topk=3)
    method = "KoBERT" if picked else "lexicon"
    if not picked:
        picked = score_fallback(text)

    print(f"\nğŸ” ë¶„ì„ë°©ë²•: {method}")
    print("ğŸ¯ ìƒìœ„ ê°ì •:", [f"{e}:{round(float(s),3)}" for e, s in picked] if picked else "ì—†ìŒ")

    books, movies, src = recommend(picked, text)
    print(f"\nğŸ“š ì±… ì¶”ì²œ Top5 ({'ì¹´íƒˆë¡œê·¸' if src=='catalog' else 'ë‚´ì¥ ëª©ë¡'}):")
    for i, b in enumerate(books, 1):
        title = b.get("title", str(b))
        extra = []
        if "author" in b and b["author"]: extra.append(b["author"])
        if "year" in b and b["year"]: extra.append(str(b["year"]))
        print(f" {i}. {title}" + (f" â€” {', '.join(extra)}" if extra else ""))

    print(f"\nğŸ¬ ì˜í™” ì¶”ì²œ Top5 ({'ì¹´íƒˆë¡œê·¸' if src=='catalog' else 'ë‚´ì¥ ëª©ë¡'}):")
    for i, m in enumerate(movies, 1):
        title = m.get("title", str(m))
        year = m.get("year", "")
        print(f" {i}. {title}" + (f" ({year})" if year else ""))

    print("")
