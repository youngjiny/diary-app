# diary_analyzer.py (v7.0 - OpenAI ê¸°ëŠ¥ ì œê±° ìµœì¢…ë³¸)

import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import re
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import font_manager
import joblib
import random
# import openai <- OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚­ì œ

# --- 1. ê¸°ë³¸ ì„¤ì • ---
MODEL_PATH = Path("sentiment_model.pkl")
VECTORIZER_PATH = Path("tfidf_vectorizer.pkl")

try:
    font_path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    st.warning("Malgun Gothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

EMOTIONS = ["í–‰ë³µ", "ì‚¬ë‘", "ìŠ¬í””", "ë¶„ë…¸", "í˜ë“¦", "ë†€ëŒ"]
TIMES = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]
TIME_KEYWORDS = { "ì•„ì¹¨": ["ì•„ì¹¨", "ì˜¤ì „", "ì¶œê·¼", "ì¼ì–´ë‚˜ì„œ"], "ì ì‹¬": ["ì ì‹¬", "ë‚®", "ì ì‹¬ì‹œê°„"], "ì €ë…": ["ì €ë…", "ì˜¤í›„", "í‡´ê·¼", "ë°¤", "ìƒˆë²½", "ìê¸° ì „", "ê¿ˆ"],}

# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
@st.cache_resource
def load_ml_resources():
    try:
        model = joblib.load(MODEL_PATH)
        vectorizer = joblib.load(VECTORIZER_PATH)
        return model, vectorizer
    except FileNotFoundError: return None, None

@st.cache_resource
def get_gsheets_connection():
    try:
        if "connections" in st.secrets and "gsheets" in st.secrets.connections:
            creds_dict = st.secrets["connections"]["gsheets"]
            scope = ['https.spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            credentials = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(credentials)
            return client
        else:
            return None
    except Exception:
        return None

def analyze_diary_ml(model, vectorizer, text):
    if not model or not vectorizer: return None, None
    sentences = re.split(r'[.?!]', text); sentences = [s.strip() for s in sentences if s.strip()]
    time_scores = { t: {e: 0 for e in EMOTIONS} for t in TIMES }
    analysis_results = []
    for sentence in sentences:
        current_time = "ì €ë…"
        for time_key, keywords in TIME_KEYWORDS.items():
            if any(keyword in sentence for keyword in keywords): current_time = time_key; break
        text_vector = vectorizer.transform([sentence])
        prediction = model.predict(text_vector)[0]
        if prediction in time_scores.get(current_time, {}):
             time_scores[current_time][prediction] += 1
        analysis_results.append({'sentence': sentence, 'predicted_emotion': prediction, 'predicted_time': current_time})
    return time_scores, analysis_results

def recommend(final_emotion):
    recommendations = {
        "í–‰ë³µ": {"ì±…": ["ê¸°ë¶„ì„ ê´€ë¦¬í•˜ë©´ ì¸ìƒì´ ê´€ë¦¬ëœë‹¤"], "ìŒì•…": ["ì•…ë®¤ - DINOSAUR"], "ì˜í™”": ["ì›”í„°ì˜ ìƒìƒì€ í˜„ì‹¤ì´ ëœë‹¤"]},
        "ì‚¬ë‘": {"ì±…": ["ì‚¬ë‘ì˜ ê¸°ìˆ "], "ìŒì•…": ["í´í‚´ - ëª¨ë“  ë‚ , ëª¨ë“  ìˆœê°„"], "ì˜í™”": ["ì–´ë°”ì›ƒ íƒ€ì„"]},
        "ìŠ¬í””": {"ì±…": ["ì•„ëª¬ë“œ"], "ìŒì•…": ["ì´ì„ í¬ - ì¸ì—°"], "ì˜í™”": ["ì½”ì½”"]},
        "ë¶„ë…¸": {"ì±…": ["ë¶„ë…¸ì˜ ì‹¬ë¦¬í•™"], "ìŒì•…": ["G-DRAGON - ì‚ë”±í•˜ê²Œ"], "ì˜í™”": ["ì„±ë‚œ ì‚¬ëŒë“¤ (ë“œë¼ë§ˆ)"]},
        "í˜ë“¦": {"ì±…": ["ì£½ê³  ì‹¶ì§€ë§Œ ë–¡ë³¶ì´ëŠ” ë¨¹ê³  ì‹¶ì–´"], "ìŒì•…": ["ì˜¥ìƒë‹¬ë¹› - ìˆ˜ê³ í–ˆì–´, ì˜¤ëŠ˜ë„"], "ì˜í™”": ["ë¦¬í‹€ í¬ë ˆìŠ¤íŠ¸"]},
        "ë†€ëŒ": {"ì±…": ["ë°ë¯¸ì•ˆ"], "ìŒì•…": ["Queen - Bohemian Rhapsody"], "ì˜í™”": ["ìœ ì „"]},
    }
    return recommendations.get(final_emotion, {"ì±…": [], "ìŒì•…": [], "ì˜í™”": []})

def save_feedback_to_gsheets(client, feedback_df):
    try:
        spreadsheet = client.open("diary_app_feedback")
        worksheet = spreadsheet.worksheet("Sheet1")
        existing_data = pd.DataFrame(worksheet.get_all_records())
        feedback_to_save = feedback_df[['text', 'label']]
        updated_df = pd.concat([existing_data, feedback_to_save], ignore_index=True)
        updated_df.drop_duplicates(subset=['text'], keep='last', inplace=True)
        worksheet.clear()
        worksheet.update([updated_df.columns.values.tolist()] + updated_df.values.tolist())
        st.success("ì†Œì¤‘í•œ í”¼ë“œë°±ì´ Google Sheetsì— ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# â­ï¸ AI ìƒì„± í•¨ìˆ˜ ëŒ€ì‹ , ê¸°ì¡´ì˜ ë‹¤ì–‘í•œ ë¬¸ì¥ ì¡°ë¦½ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
def generate_random_diary():
    """ë‹¤ì–‘í•˜ê³  ê¸´ í…ŒìŠ¤íŠ¸ìš© ëœë¤ ì¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    morning_starts = [ "ì•„ì¹¨ ì¼ì° ì¼ì–´ë‚˜ ìƒì¾Œí•˜ê²Œ í•˜ë£¨ë¥¼ ì‹œì‘í–ˆë‹¤.", "ëŠ¦ì ì„ ìì„œ í—ˆë‘¥ì§€ë‘¥ ì¶œê·¼ ì¤€ë¹„ë¥¼ í–ˆë‹¤.", "ì˜¤ëŠ˜ì€ ì¬íƒê·¼ë¬´ë¼ ì—¬ìœ ë¡­ê²Œ ì•„ì¹¨ì„ ë§ì´í–ˆë‹¤.", "ì•„ì¹¨ë¶€í„° ë¹„ê°€ ì™€ì„œ ê·¸ëŸ°ì§€ ê¸°ë¶„ì´ ì¡°ê¸ˆ ê°€ë¼ì•‰ì•˜ë‹¤." ]
    midday_events = [ "ì ì‹¬ìœ¼ë¡œ ë¨¹ì€ íŒŒìŠ¤íƒ€ê°€ ì •ë§ ë§›ìˆì–´ì„œ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.", "ë™ë£Œì—ê²Œ ì¹­ì°¬ì„ ë“¤ì–´ì„œ ë¿Œë“¯í–ˆë‹¤.", "ìƒê°ë³´ë‹¤ ì¼ì´ ì¼ì° ëë‚˜ì„œ ì ì‹œ íœ´ì‹ì„ ì¦ê²¼ë‹¤.", "ì¹´í˜ì—ì„œ ë§ˆì‹  ì»¤í”¼ê°€ ìœ ë‚œíˆ í–¥ê¸‹í•´ì„œ ê¸°ë¶„ì´ ì „í™˜ëë‹¤.", "ì˜¤ëœë§Œì— ì¹œêµ¬ì™€ ì ì‹¬ ì•½ì†ì„ ì¡ê³  ì¦ê²ê²Œ ìˆ˜ë‹¤ë¥¼ ë–¨ì—ˆë‹¤.", "ì˜¤í›„ íšŒì˜ê°€ ë„ˆë¬´ ê¸¸ì–´ì ¸ì„œ ì§„ì´ ë¹ ì¡Œë‹¤.", "ì‚¬ì†Œí•œ ì‹¤ìˆ˜ ë•Œë¬¸ì— íŒ€ì¥ë‹˜ê»˜ ì§€ì ì„ ë°›ì•„ì„œ ì†ìƒí–ˆë‹¤.", "ê°‘ìê¸° ì²˜ë¦¬í•´ì•¼ í•  ê¸‰í•œ ì—…ë¬´ê°€ ìƒê²¨ì„œ ì •ì‹ ì—†ì´ ë°”ë¹´ë‹¤.", "ì ì‹¬ì„ ê¸‰í•˜ê²Œ ë¨¹ì—ˆë”ë‹ˆ ì†ì´ ë”ë¶€ë£©í•˜ê³  í˜ë“¤ì—ˆë‹¤.", "ë¯¿ì—ˆë˜ ë™ë£Œì™€ ì˜ê²¬ ë‹¤íˆ¼ì´ ìˆì–´ì„œ ë§ˆìŒì´ ìƒí–ˆë‹¤.", "ì˜¤í›„ ë‚´ë‚´ ì¡°ìš©íˆ ë‚´ ì—…ë¬´ì—ë§Œ ì§‘ì¤‘í–ˆë‹¤.", "ì˜¤ëœë§Œì— ì„œì ì— ë“¤ëŸ¬ì„œ ì±… êµ¬ê²½ì„ í–ˆë‹¤.", "ë‹¤ìŒ ì£¼ ê³„íšì„ ë¯¸ë¦¬ ì„¸ìš°ë©° ì‹œê°„ì„ ë³´ëƒˆë‹¤." ]
    evening_conclusions = [ "í‡´ê·¼ í›„ ìš´ë™ì„ í•˜ê³  ë‚˜ë‹ˆ ëª¸ì€ í˜ë“¤ì—ˆì§€ë§Œ ê¸°ë¶„ì€ ìƒì¾Œí–ˆë‹¤.", "ìê¸° ì „ ë³¸ ì˜í™”ê°€ ë„ˆë¬´ ê°ë™ì ì´ì–´ì„œ ì—¬ìš´ì´ ë‚¨ëŠ”ë‹¤.", "ì €ë…ì— ë§›ìˆëŠ” ìŒì‹ì„ ë¨¹ìœ¼ë©° í•˜ë£¨ì˜ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ í’€ì—ˆë‹¤.", "í•˜ë£¨ ì¢…ì¼ í˜ë“¤ì—ˆëŠ”ë°, ìê¸° ì „ ë“¤ì€ ìŒì•… ë•ë¶„ì— ë§ˆìŒì´ í¸ì•ˆí•´ì¡Œë‹¤.", "ë³„ì¼ ì—†ì´ ë¬´ë‚œí•˜ê²Œ í•˜ë£¨ê°€ ë§ˆë¬´ë¦¬ë˜ì—ˆë‹¤." ]
    
    diary_parts = []
    diary_parts.append(random.choice(morning_starts))
    num_midday_events = random.randint(1, 3)
    selected_midday_events = random.sample(midday_events, num_midday_events)
    diary_parts.extend(selected_midday_events)
    diary_parts.append(random.choice(evening_conclusions))
    return " ".join(diary_parts)

# --- 3. UI ë¡œì§ (ì½œë°± í•¨ìˆ˜ ì •ì˜) ---
def handle_random_click():
    st.session_state.diary_text = generate_random_diary()
    st.session_state.analysis_results = None

def handle_analyze_click(model, vectorizer):
    diary_content = st.session_state.diary_text
    if not diary_content.strip():
        st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    elif model is None or vectorizer is None:
        st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GitHubì—ì„œ ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner('AIê°€ ì¼ê¸°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            _, results = analyze_diary_ml(model, vectorizer, diary_content)
            st.session_state.analysis_results = results

# --- 4. Streamlit UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ“Š í•˜ë£¨ ê°ì • ë¶„ì„ ë¦¬í¬íŠ¸ (v7.0)")

model, vectorizer = load_ml_resources()

if 'diary_text' not in st.session_state: st.session_state.diary_text = ""
if 'analysis_results' not in st.session_state: st.session_state.analysis_results = None

col1, col2 = st.columns([3, 1])
with col1:
    st.text_area("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì‘ì„±í•´ë³´ì„¸ìš”:", key='diary_text', height=250)
with col2:
    st.write(" "); st.write(" ")
    # â­ï¸ ë²„íŠ¼ ì´ë¦„ ì›ë˜ëŒ€ë¡œ ë³€ê²½
    st.button("ğŸ”„ ëœë¤ ì¼ê¸° ìƒì„±", on_click=handle_random_click)
    st.button("ğŸ” ë‚´ í•˜ë£¨ ê°ì • ë¶„ì„í•˜ê¸°", type="primary", on_click=handle_analyze_click, args=(model, vectorizer))

if st.session_state.analysis_results:
    # ... (ì´í•˜ ë¶„ì„ ê²°ê³¼, ì¶”ì²œ, í”¼ë“œë°± UIëŠ” ì´ì „ê³¼ ë™ì¼)
    if model is None or vectorizer is None:
        st.error("ëª¨ë¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GitHub ì €ì¥ì†Œì— pkl íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        scores_data, _ = analyze_diary_ml(model, vectorizer, st.session_state.diary_text)
        df_scores = pd.DataFrame(scores_data).T
        if df_scores.sum().sum() > 0:
            st.subheader("ğŸ•’ ì‹œê°„ëŒ€ë³„ ê°ì • ë¶„ì„ ê²°ê³¼")
            final_emotion = df_scores.sum().idxmax()
            res_col1, res_col2 = st.columns([1.2, 1])
            with res_col1:
                fig, ax = plt.subplots(figsize=(8, 5))
                df_scores.plot(kind='bar', stacked=True, ax=ax, width=0.8, colormap='Pastel1', edgecolor='grey')
                ax.set_title("ì‹œê°„ëŒ€ë³„ ê°ì • ë³€í™” ê·¸ë˜í”„", fontsize=16); ax.set_ylabel("ê°ì • ë¬¸ì¥ ìˆ˜", fontsize=12)
                ax.set_xticklabels(df_scores.index, rotation=0, fontsize=12)
                ax.legend(title="ê°ì •", bbox_to_anchor=(1.02, 1), loc='upper left'); plt.tight_layout()
                st.pyplot(fig)
            with res_col2:
                st.dataframe(df_scores.style.format("{:.0f}").background_gradient(cmap='viridis'))
                st.success(f"ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì¢…í•©í•´ ë³´ë©´, **'{final_emotion}'**ì˜ ê°ì •ì´ ê°€ì¥ ì»¸ë„¤ìš”!")
            st.divider()
            st.subheader(f"'{final_emotion}' ê°ì •ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ì¶”ì²œ")
            recs = recommend(final_emotion)
            rec_col1, rec_col2, rec_col3 = st.columns(3)
            with rec_col1:
                st.write("ğŸ“š **ì´ëŸ° ì±…ì€ ì–´ë•Œìš”?**")
                for item in recs['ì±…']: st.write(f"- {item}")
            with rec_col2:
                st.write("ğŸµ **ì´ëŸ° ìŒì•…ë„ ë“¤ì–´ë³´ì„¸ìš”?**")
                for item in recs['ìŒì•…']: st.write(f"- {item}")
            with rec_col3:
                st.write("ğŸ¬ **ì´ëŸ° ì˜í™”/ë“œë¼ë§ˆë„ ì¶”ì²œí•´ìš”?**")
                for item in recs['ì˜í™”']: st.write(f"- {item}")
            st.divider()
            st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ í”¼ë“œë°±")
            feedback_data = []
            for i, result in enumerate(st.session_state.analysis_results):
                st.markdown(f"> {result['sentence']}")
                cols = st.columns([1, 1])
                with cols[0]:
                    correct_time = st.radio("ì´ ë¬¸ì¥ì˜ ì‹œê°„ëŒ€ëŠ”?", TIMES, index=TIMES.index(result['predicted_time']), key=f"time_{i}", horizontal=True)
                with cols[1]:
                    try:
                        emotion_index = EMOTIONS.index(result['predicted_emotion'])
                    except ValueError:
                        emotion_index = 0
                    correct_emotion = st.selectbox("ì´ ë¬¸ì¥ì˜ ì§„ì§œ ê°ì •ì€?", EMOTIONS, index=emotion_index, key=f"emotion_{i}")
                feedback_data.append({'text': result['sentence'], 'label': correct_emotion, 'time': correct_time})
                st.write("---")
            if st.button("í”¼ë“œë°± ì œì¶œí•˜ê¸°"):
                client = get_gsheets_connection()
                if client:
                    changed_feedback = []
                    for i, row in enumerate(pd.DataFrame(feedback_data).to_dict('records')):
                        original = st.session_state.analysis_results[i]
                        if row['label'] != original['predicted_emotion'] or row['time'] != original['predicted_time']:
                            changed_feedback.append({'text': row['text'], 'label': row['label']})
                    if changed_feedback:
                        final_feedback_df = pd.DataFrame(changed_feedback)
                        save_feedback_to_gsheets(client, final_feedback_df)
                        st.session_state.analysis_results = None; st.rerun()
                    else: st.info("ìˆ˜ì •ëœ ë‚´ìš©ì´ ì—†ë„¤ìš”. AIê°€ ì˜ ë§ì·„ë‚˜ ë³´ë„¤ìš”! ğŸ˜„")
                else:
                    st.error("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

with st.expander("í”¼ë“œë°± ì €ì¥ í˜„í™© ë³´ê¸° (Google Sheets)"):
    client = get_gsheets_connection()
    if client:
        try:
            spreadsheet = client.open("diary_app_feedback")
            worksheet = spreadsheet.worksheet("Sheet1")
            df = pd.DataFrame(worksheet.get_all_records())
            st.dataframe(df)
            st.info(f"í˜„ì¬ ì´ **{len(df)}ê°œ**ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        except Exception:
            st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Secrets, Google Sheets ê³µìœ /ì‹œíŠ¸ì´ë¦„ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.error("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")