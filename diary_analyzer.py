# diary_analyzer.py (v6.1 - ìµœì¢… ì•ˆì •í™” ë²„ì „)

import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import re
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import font_manager
import joblib
import random

# --- 1. ê¸°ë³¸ ì„¤ì • ---
MODEL_PATH = Path("sentiment_model.pkl")
VECTORIZER_PATH = Path("tfidf_vectorizer.pkl")

try:
    font_path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    st.warning("Malgun Gothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

EMOTIONS = ["ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ìš°ìš¸", "ì‚¬ë‘"]
TIMES = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]
TIME_KEYWORDS = { "ì•„ì¹¨": ["ì•„ì¹¨", "ì˜¤ì „", "ì¶œê·¼", "ì¼ì–´ë‚˜ì„œ"], "ì ì‹¬": ["ì ì‹¬", "ë‚®", "ì ì‹¬ì‹œê°„"], "ì €ë…": ["ì €ë…", "ì˜¤í›„", "í‡´ê·¼", "ë°¤", "ìƒˆë²½", "ìê¸° ì „", "ê¿ˆ"],}

# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
@st.cache_resource
def load_ml_resources():
    try:
        model = joblib.load(MODEL_PATH)
        vectorizer = joblib.load(VECTORIZER_PATH)
        return model, vectorizer
    except FileNotFoundError: return None, None

def analyze_diary_ml(model, vectorizer, text):
    if not model or not vectorizer: return None, None
    sentences = re.split(r'[.?!]', text); sentences = [s.strip() for s in sentences if s.strip()]
    time_scores = { t: {e: 0 for e in EMOTIONS} for t in TIMES }
    analysis_results = []
    for sentence in sentences:
        current_time = "ì €ë…"
        for time_key, keywords in TIME_KEYWORDS.items():
            if any(keyword in sentence for keyword in keywords): current_time = time_key; break
        text_vector = vectorizer.transform([sentence])
        prediction = model.predict(text_vector)[0]
        if prediction in time_scores.get(current_time, {}):
             time_scores[current_time][prediction] += 1
        analysis_results.append({'sentence': sentence, 'predicted_emotion': prediction, 'predicted_time': current_time})
    return time_scores, analysis_results

def recommend(final_emotion):
    recommendations = {"ê¸°ì¨": {"ì±…": ["ì˜¤ëŠ˜ ë°¤, ì„¸ê³„ì—ì„œ ì´ ì‚¬ë‘ì´ ì‚¬ë¼ì§„ë‹¤ í•´ë„"], "ìŒì•…": ["ìœ¤í•˜ - ì‚¬ê±´ì˜ ì§€í‰ì„ "], "ì˜í™”": ["íƒ‘ê±´: ë§¤ë²„ë¦­"]},"ìŠ¬í””": {"ì±…": ["ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì "], "ìŒì•…": ["ê¹€ê´‘ì„ - ì„œë¥¸ ì¦ˆìŒì—"], "ì˜í™”": ["ì½”ì½”"]},"ë¶„ë…¸": {"ì±…": ["ì—­í–‰ì"], "ìŒì•…": ["(ì—¬ì)ì•„ì´ë“¤ - TOMBOY"], "ì˜í™”": ["ë²”ì£„ë„ì‹œ2"]},"ìš°ìš¸": {"ì±…": ["ë¶ˆí¸í•œ í¸ì˜ì "], "ìŒì•…": ["ì•„ì´ìœ  - ë°¤í¸ì§€"], "ì˜í™”": ["ë¦¬í‹€ í¬ë ˆìŠ¤íŠ¸"]},"ì‚¬ë‘": {"ì±…": ["ë‚˜ì˜ í•´ë°©ì¼ì§€"], "ìŒì•…": ["ì„±ì‹œê²½ - ë„ˆì˜ ëª¨ë“  ìˆœê°„"], "ì˜í™”": ["í—¤ì–´ì§ˆ ê²°ì‹¬"]},}
    return recommendations.get(final_emotion, {"ì±…": [], "ìŒì•…": [], "ì˜í™”": []})

@st.cache_resource
def get_gsheets_connection():
    creds_dict = st.secrets["connections"]["gsheets"]
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    credentials = Credentials.from_service_account_info(creds_dict, scopes=scope)
    client = gspread.authorize(credentials)
    return client

def save_feedback_to_gsheets(client, feedback_df):
    try:
        spreadsheet = client.open("diary_app_feedback")
        worksheet = spreadsheet.worksheet("Sheet1")
        existing_data = pd.DataFrame(worksheet.get_all_records())
        feedback_to_save = feedback_df[['text', 'label']]
        updated_df = pd.concat([existing_data, feedback_to_save], ignore_index=True)
        updated_df.drop_duplicates(subset=['text'], keep='last', inplace=True)
        worksheet.clear()
        worksheet.update([updated_df.columns.values.tolist()] + updated_df.values.tolist())
        st.success("ì†Œì¤‘í•œ í”¼ë“œë°±ì´ Google Sheetsì— ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def generate_random_diary():
    morning = ["ì•„ì¹¨ì— ìƒì¾Œí•˜ê²Œ ì¼ì–´ë‚¬ë‹¤.", "ì¶œê·¼ê¸¸ ì§€í•˜ì² ì— ì‚¬ëŒì´ ë„ˆë¬´ ë§ì•„ í˜ë“¤ì—ˆë‹¤."]
    afternoon = ["ì ì‹¬ìœ¼ë¡œ ë§›ìˆëŠ” íŒŒìŠ¤íƒ€ë¥¼ ë¨¹ì–´ì„œ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.", "ì˜¤í›„ íšŒì˜ê°€ ê¸¸ì–´ì ¸ì„œ ë„ˆë¬´ ì§€ì³¤ë‹¤."]
    evening = ["í‡´ê·¼í•˜ê³  ìš´ë™ì„ í•˜ë‹ˆ ê°œìš´í–ˆë‹¤.", "ìê¸° ì „ì— ë³¸ ì˜í™”ê°€ ì •ë§ ê°ë™ì ì´ì—ˆë‹¤."]
    return f"{random.choice(morning)} {random.choice(afternoon)} {random.choice(evening)}"

# --- 3. Streamlit UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ“Š í•˜ë£¨ ê°ì • ë¶„ì„ ë¦¬í¬íŠ¸ (v6.1)")

# ëª¨ë¸ ë¡œë”©ì€ ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ!
model, vectorizer = load_ml_resources()

if 'diary_text' not in st.session_state: st.session_state.diary_text = ""
if 'analysis_results' not in st.session_state: st.session_state.analysis_results = None

col1, col2 = st.columns([3, 1])
with col1:
    st.text_area("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì‘ì„±í•´ë³´ì„¸ìš”:", key='diary_text', height=250)
with col2:
    st.write(" "); st.write(" ")
    if st.button("ğŸ”„ ëœë¤ ì¼ê¸° ìƒì„±"):
        st.session_state.diary_text = generate_random_diary()
        st.session_state.analysis_results = None
        st.rerun()
    if st.button("ğŸ” ë‚´ í•˜ë£¨ ê°ì • ë¶„ì„í•˜ê¸°", type="primary"):
        if not st.session_state.diary_text.strip():
            st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif model is None or vectorizer is None:
            st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        else:
            with st.spinner('AIê°€ ì¼ê¸°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                _, results = analyze_diary_ml(model, vectorizer, st.session_state.diary_text)
                st.session_state.analysis_results = results

if st.session_state.analysis_results:
    scores_data, _ = analyze_diary_ml(model, vectorizer, st.session_state.diary_text)
    df_scores = pd.DataFrame(scores_data).T
    if df_scores.sum().sum() > 0:
        # (ì´í•˜ ì‹œê°í™” ë° í”¼ë“œë°± UI ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼)
        st.subheader("ğŸ•’ ì‹œê°„ëŒ€ë³„ ê°ì • ë¶„ì„ ê²°ê³¼")
        final_emotion = df_scores.sum().idxmax()
        res_col1, res_col2 = st.columns([1.2, 1])
        with res_col1:
            fig, ax = plt.subplots(figsize=(8, 5))
            df_scores.plot(kind='bar', stacked=True, ax=ax, width=0.8, colormap='Pastel1', edgecolor='grey')
            ax.set_title("ì‹œê°„ëŒ€ë³„ ê°ì • ë³€í™” ê·¸ë˜í”„", fontsize=16); ax.set_ylabel("ê°ì • ë¬¸ì¥ ìˆ˜", fontsize=12)
            ax.set_xticklabels(df_scores.index, rotation=0, fontsize=12)
            ax.legend(title="ê°ì •", bbox_to_anchor=(1.02, 1), loc='upper left'); plt.tight_layout()
            st.pyplot(fig)
        with res_col2:
            st.dataframe(df_scores.style.format("{:.0f}").background_gradient(cmap='viridis'))
            st.success(f"ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì¢…í•©í•´ ë³´ë©´, **'{final_emotion}'**ì˜ ê°ì •ì´ ê°€ì¥ ì»¸ë„¤ìš”!")
        st.divider()
        st.subheader(f"'{final_emotion}' ê°ì •ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ì¶”ì²œ")
        recs = recommend(final_emotion)
        rec_col1, rec_col2, rec_col3 = st.columns(3)
        with rec_col1:
            st.write("ğŸ“š **ì´ëŸ° ì±…ì€ ì–´ë•Œìš”?**"); [st.write(f"- {item}") for item in recs['ì±…']]
        with rec_col2:
            st.write("ğŸµ **ì´ëŸ° ìŒì•…ë„ ë“¤ì–´ë³´ì„¸ìš”!**"); [st.write(f"- {item}") for item in recs['ìŒì•…']]
        with rec_col3:
            st.write("ğŸ¬ **ì´ëŸ° ì˜í™”/ë“œë¼ë§ˆë„ ì¶”ì²œí•´ìš”!**"); [st.write(f"- {item}") for item in recs['ì˜í™”']]
        st.divider()
        st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ í”¼ë“œë°±")
        feedback_data = []
        for i, result in enumerate(st.session_state.analysis_results):
            st.markdown(f"> {result['sentence']}")
            cols = st.columns([1, 1])
            with cols[0]:
                correct_time = st.radio("ì´ ë¬¸ì¥ì˜ ì‹œê°„ëŒ€ëŠ”?", TIMES, index=TIMES.index(result['predicted_time']), key=f"time_{i}", horizontal=True)
            with cols[1]:
                correct_emotion = st.selectbox("ì´ ë¬¸ì¥ì˜ ì§„ì§œ ê°ì •ì€?", EMOTIONS, index=EMOTIONS.index(result['predicted_emotion']), key=f"emotion_{i}")
            feedback_data.append({'text': result['sentence'], 'label': correct_emotion, 'time': correct_time})
            st.write("---")
        if st.button("í”¼ë“œë°± ì œì¶œí•˜ê¸°"):
            client = get_gsheets_connection()
            changed_feedback = []
            for i, row in enumerate(pd.DataFrame(feedback_data).to_dict('records')):
                original = st.session_state.analysis_results[i]
                if row['label'] != original['predicted_emotion'] or row['time'] != original['predicted_time']:
                    changed_feedback.append({'text': row['text'], 'label': row['label']})
            if changed_feedback:
                final_feedback_df = pd.DataFrame(changed_feedback)
                save_feedback_to_gsheets(client, final_feedback_df)
                st.session_state.analysis_results = None; st.rerun()
            else: st.info("ìˆ˜ì •ëœ ë‚´ìš©ì´ ì—†ë„¤ìš”. AIê°€ ì˜ ë§ì·„ë‚˜ ë³´ë„¤ìš”! ğŸ˜„")

# --- í”¼ë“œë°± ì €ì¥ í˜„í™© ë³´ê¸° ---
with st.expander("í”¼ë“œë°± ì €ì¥ í˜„í™© ë³´ê¸° (Google Sheets)"):
    try:
        client = get_gsheets_connection()
        spreadsheet = client.open("diary_app_feedback")
        worksheet = spreadsheet.worksheet("Sheet1")
        df = pd.DataFrame(worksheet.get_all_records())
        st.dataframe(df)
        st.info(f"í˜„ì¬ ì´ **{len(df)}ê°œ**ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        st.error("1. Streamlit Secretsì— ì¸ì¦ ì •ë³´ê°€ ì •í™•í•œê°€ìš”?")
        st.error("2. Google Sheets íŒŒì¼ì´ ì„œë¹„ìŠ¤ ê³„ì •ì— 'í¸ì§‘ì'ë¡œ ê³µìœ ë˜ì—ˆë‚˜ìš”?")
        st.error(f"ì˜¤ë¥˜ ë©”ì‹œì§€: {e}")