# diary_analyzer.py (v5.1 - ê³µì‹ GSheets ì—°ë™ ìµœì¢…ë³¸)

import streamlit as st
# from streamlit_gsheets import GSheetsConnection  <- â­ï¸ ì´ ì¤„ì„ ì™„ì „íˆ ì‚­ì œí•©ë‹ˆë‹¤.
import re
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import font_manager
import joblib
import random

# --- 1. ê¸°ë³¸ ì„¤ì • ---
MODEL_PATH = Path("sentiment_model.pkl")
VECTORIZER_PATH = Path("tfidf_vectorizer.pkl")

# ... (í°íŠ¸ ì„¤ì •, EMOTIONS, TIMES ë“± ì´ì „ê³¼ ë™ì¼)
try:
    font_path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    st.warning("Malgun Gothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

EMOTIONS = ["ê¸°ì¨", "ìŠ¬í””", "ë¶„ë…¸", "ìš°ìš¸", "ì‚¬ë‘"]
TIMES = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]
TIME_KEYWORDS = { "ì•„ì¹¨": ["ì•„ì¹¨", "ì˜¤ì „", "ì¶œê·¼", "ì¼ì–´ë‚˜ì„œ"], "ì ì‹¬": ["ì ì‹¬", "ë‚®", "ì ì‹¬ì‹œê°„"], "ì €ë…": ["ì €ë…", "ì˜¤í›„", "í‡´ê·¼", "ë°¤", "ìƒˆë²½", "ìê¸° ì „", "ê¿ˆ"],}


# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
@st.cache_resource
def load_ml_resources():
    try:
        model = joblib.load(MODEL_PATH)
        vectorizer = joblib.load(VECTORIZER_PATH)
        return model, vectorizer
    except FileNotFoundError: return None, None

model, vectorizer = load_ml_resources()

# â­ï¸ Google Sheets ì—°ê²° ì„¤ì • (ë” ê°„ë‹¨í•˜ê³  ì˜¬ë°”ë¥¸ ë°©ì‹)
# Secretsì˜ [connections.gsheets] ì œëª©ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
conn = st.connection("gsheets", type="streamlit_gsheets.GSheetsConnection")

def save_feedback_to_gsheets(feedback_df):
    """í”¼ë“œë°±ì„ Google Sheetsì— ë°”ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        existing_data = conn.read(worksheet="Sheet1") # â­ï¸ ë³¸ì¸ì˜ ì‹œíŠ¸ ì´ë¦„ í™•ì¸! (ë³´í†µ Sheet1)
        feedback_to_save = feedback_df[['text', 'label']]
        updated_df = pd.concat([existing_data, feedback_to_save], ignore_index=True)
        updated_df.drop_duplicates(subset=['text'], keep='last', inplace=True)
        conn.update(worksheet="Sheet1", data=updated_df) # â­ï¸ ë³¸ì¸ì˜ ì‹œíŠ¸ ì´ë¦„ í™•ì¸!
        st.success("ì†Œì¤‘í•œ í”¼ë“œë°±ì´ Google Sheetsì— ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("Google Sheets ê³µìœ  ì„¤ì • ë° ì‹œíŠ¸ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ... (analyze_diary_ml, recommend, generate_random_diary ë“± ë‚˜ë¨¸ì§€ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
# ... (UI êµ¬ì„± ë° ë‚˜ë¨¸ì§€ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
def analyze_diary_ml(text):
    if not model or not vectorizer: return None, None
    sentences = re.split(r'[.?!]', text); sentences = [s.strip() for s in sentences if s.strip()]
    time_scores = { t: {e: 0 for e in EMOTIONS} for t in TIMES }
    analysis_results = []
    for sentence in sentences:
        current_time = "ì €ë…"
        for time_key, keywords in TIME_KEYWORDS.items():
            if any(keyword in sentence for keyword in keywords): current_time = time_key; break
        text_vector = vectorizer.transform([sentence])
        prediction = model.predict(text_vector)[0]
        if prediction in time_scores[current_time]: time_scores[current_time][prediction] += 1
        analysis_results.append({'sentence': sentence, 'predicted_emotion': prediction, 'predicted_time': current_time})
    return time_scores, analysis_results
def recommend(final_emotion):
    recommendations = {"ê¸°ì¨": {"ì±…": ["ì˜¤ëŠ˜ ë°¤, ì„¸ê³„ì—ì„œ ì´ ì‚¬ë‘ì´ ì‚¬ë¼ì§„ë‹¤ í•´ë„"], "ìŒì•…": ["ìœ¤í•˜ - ì‚¬ê±´ì˜ ì§€í‰ì„ "], "ì˜í™”": ["íƒ‘ê±´: ë§¤ë²„ë¦­"]},"ìŠ¬í””": {"ì±…": ["ë‹¬ëŸ¬êµ¬íŠ¸ ê¿ˆ ë°±í™”ì "], "ìŒì•…": ["ê¹€ê´‘ì„ - ì„œë¥¸ ì¦ˆìŒì—"], "ì˜í™”": ["ì½”ì½”"]},"ë¶„ë…¸": {"ì±…": ["ì—­í–‰ì"], "ìŒì•…": ["(ì—¬ì)ì•„ì´ë“¤ - TOMBOY"], "ì˜í™”": ["ë²”ì£„ë„ì‹œ2"]},"ìš°ìš¸": {"ì±…": ["ë¶ˆí¸í•œ í¸ì˜ì "], "ìŒì•…": ["ì•„ì´ìœ  - ë°¤í¸ì§€"], "ì˜í™”": ["ë¦¬í‹€ í¬ë ˆìŠ¤íŠ¸"]},"ì‚¬ë‘": {"ì±…": ["ë‚˜ì˜ í•´ë°©ì¼ì§€"], "ìŒì•…": ["ì„±ì‹œê²½ - ë„ˆì˜ ëª¨ë“  ìˆœê°„"], "ì˜í™”": ["í—¤ì–´ì§ˆ ê²°ì‹¬"]},}
    return recommendations.get(final_emotion, {"ì±…": [], "ìŒì•…": [], "ì˜í™”": []})
def generate_random_diary():
    morning = ["ì•„ì¹¨ì— ìƒì¾Œí•˜ê²Œ ì¼ì–´ë‚¬ë‹¤.", "ì¶œê·¼ê¸¸ ì§€í•˜ì² ì— ì‚¬ëŒì´ ë„ˆë¬´ ë§ì•„ í˜ë“¤ì—ˆë‹¤.", "ì¼ì–´ë‚˜ìë§ˆì ë§ˆì‹  ì»¤í”¼ê°€ ì •ë§ ë§›ìˆì—ˆë‹¤."]
    afternoon = ["ì ì‹¬ìœ¼ë¡œ ë§›ìˆëŠ” íŒŒìŠ¤íƒ€ë¥¼ ë¨¹ì–´ì„œ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.", "ì˜¤í›„ íšŒì˜ê°€ ê¸¸ì–´ì ¸ì„œ ë„ˆë¬´ ì§€ì³¤ë‹¤.", "ë™ë£Œì™€ ì ì‹œ ë‚˜ëˆˆ ìˆ˜ë‹¤ê°€ ì¦ê±°ì› ë‹¤."]
    evening = ["í‡´ê·¼í•˜ê³  ìš´ë™ì„ í•˜ë‹ˆ ê°œìš´í–ˆë‹¤.", "ì €ë… ì•½ì†ì´ ê°‘ìê¸° ì·¨ì†Œë˜ì–´ ì„œìš´í–ˆë‹¤.", "ìê¸° ì „ì— ë³¸ ì˜í™”ê°€ ì •ë§ ê°ë™ì ì´ì—ˆë‹¤.", "í•˜ë£¨ ì¢…ì¼ ìŒ“ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ì— í™”ê°€ ë‚¬ë‹¤."]
    return f"{random.choice(morning)} {random.choice(afternoon)} {random.choice(evening)}"
def handle_random_click():
    st.session_state.diary_text = generate_random_diary()
    st.session_state.analysis_results = None
def handle_analyze_click():
    diary_content = st.session_state.diary_text
    if not diary_content.strip(): st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    elif model is None or vectorizer is None: st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        with st.spinner('AIê°€ ì¼ê¸°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            _, results = analyze_diary_ml(diary_content)
            st.session_state.analysis_results = results
st.set_page_config(layout="wide")
st.title("ğŸ“Š í•˜ë£¨ ê°ì • ë¶„ì„ ë¦¬í¬íŠ¸ (v5.1)")
if 'diary_text' not in st.session_state: st.session_state.diary_text = ""
if 'analysis_results' not in st.session_state: st.session_state.analysis_results = None
col1, col2 = st.columns([3, 1])
with col1:
    st.text_area("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì‘ì„±í•´ë³´ì„¸ìš”:", key='diary_text', height=250)
with col2:
    st.write(" "); st.write(" ")
    st.button("ğŸ”„ ëœë¤ ì¼ê¸° ìƒì„±", on_click=handle_random_click)
    st.button("ğŸ” ë‚´ í•˜ë£¨ ê°ì • ë¶„ì„í•˜ê¸°", type="primary", on_click=handle_analyze_click)
if st.session_state.analysis_results:
    scores_data, _ = analyze_diary_ml(st.session_state.diary_text)
    df_scores = pd.DataFrame(scores_data).T
    if df_scores.sum().sum() > 0:
        st.subheader("ğŸ•’ ì‹œê°„ëŒ€ë³„ ê°ì • ë¶„ì„ ê²°ê³¼")
        final_emotion = df_scores.sum().idxmax()
        res_col1, res_col2 = st.columns([1.2, 1])
        with res_col1:
            fig, ax = plt.subplots(figsize=(8, 5))
            df_scores.plot(kind='bar', stacked=True, ax=ax, width=0.8, colormap='Pastel1', edgecolor='grey')
            ax.set_title("ì‹œê°„ëŒ€ë³„ ê°ì • ë³€í™” ê·¸ë˜í”„", fontsize=16); ax.set_ylabel("ê°ì • ë¬¸ì¥ ìˆ˜", fontsize=12)
            ax.set_xticklabels(df_scores.index, rotation=0, fontsize=12)
            ax.legend(title="ê°ì •", bbox_to_anchor=(1.02, 1), loc='upper left'); plt.tight_layout()
            st.pyplot(fig)
        with res_col2:
            st.dataframe(df_scores.style.format("{:.0f}").background_gradient(cmap='viridis'))
            st.success(f"ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì¢…í•©í•´ ë³´ë©´, **'{final_emotion}'**ì˜ ê°ì •ì´ ê°€ì¥ ì»¸ë„¤ìš”!")
        st.divider()
        st.subheader(f"'{final_emotion}' ê°ì •ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ì¶”ì²œ")
        recs = recommend(final_emotion)
        rec_col1, rec_col2, rec_col3 = st.columns(3)
        with rec_col1:
            st.write("ğŸ“š **ì´ëŸ° ì±…ì€ ì–´ë•Œìš”?**")
            for item in recs['ì±…']: st.write(f"- {item}")
        with rec_col2:
            st.write("ğŸµ **ì´ëŸ° ìŒì•…ë„ ë“¤ì–´ë³´ì„¸ìš”!**")
            for item in recs['ìŒì•…']: st.write(f"- {item}")
        with rec_col3:
            st.write("ğŸ¬ **ì´ëŸ° ì˜í™”/ë“œë¼ë§ˆë„ ì¶”ì²œí•´ìš”!**")
            for item in recs['ì˜í™”']: st.write(f"- {item}")
        st.divider()
        st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ í”¼ë“œë°±")
        feedback_data = []
        for i, result in enumerate(st.session_state.analysis_results):
            st.markdown(f"> {result['sentence']}")
            cols = st.columns([1, 1])
            with cols[0]:
                correct_time = st.radio("ì´ ë¬¸ì¥ì˜ ì‹œê°„ëŒ€ëŠ”?", TIMES, index=TIMES.index(result['predicted_time']), key=f"time_{i}", horizontal=True)
            with cols[1]:
                correct_emotion = st.selectbox("ì´ ë¬¸ì¥ì˜ ì§„ì§œ ê°ì •ì€?", EMOTIONS, index=EMOTIONS.index(result['predicted_emotion']), key=f"emotion_{i}")
            feedback_data.append({'text': result['sentence'], 'label': correct_emotion, 'time': correct_time})
            st.write("---")
        if st.button("í”¼ë“œë°± ì œì¶œí•˜ê¸°"):
            changed_feedback = []
            for i, row in enumerate(pd.DataFrame(feedback_data).to_dict('records')):
                original = st.session_state.analysis_results[i]
                if row['label'] != original['predicted_emotion'] or row['time'] != original['predicted_time']:
                    changed_feedback.append({'text': row['text'], 'label': row['label']})
            if changed_feedback:
                final_feedback_df = pd.DataFrame(changed_feedback)
                save_feedback_to_gsheets(final_feedback_df) # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½ í™•ì¸
                st.session_state.analysis_results = None; st.rerun()
            else: st.info("ìˆ˜ì •ëœ ë‚´ìš©ì´ ì—†ë„¤ìš”. AIê°€ ì˜ ë§ì·„ë‚˜ ë³´ë„¤ìš”! ğŸ˜„")
with st.expander("í”¼ë“œë°± ì €ì¥ í˜„í™© ë³´ê¸° (Google Sheets)"):
    try:
        df = conn.read(worksheet="Sheet1", usecols=[0, 1], ttl="5m")
        st.write(f"í˜„ì¬ ì´ **{len(df)}ê°œ**ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.dataframe(df.tail(5))
    except Exception as e:
        st.write("ì•„ì§ ì €ì¥ëœ ë°ì´í„°ê°€ ì—†ê±°ë‚˜, ì‹œíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")