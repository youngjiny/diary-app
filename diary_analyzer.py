# diary_analyzer.py (v6.3 - 6ê°€ì§€ ê°ì • ìµœì¢… ë²„ì „)

import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import re
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import font_manager
import joblib
import random

# --- 1. ê¸°ë³¸ ì„¤ì • ---
MODEL_PATH = Path("sentiment_model.pkl")
VECTORIZER_PATH = Path("tfidf_vectorizer.pkl")

try:
    font_path = "c:/Windows/Fonts/malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    plt.rc('font', family=font_name)
except FileNotFoundError:
    st.warning("Malgun Gothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# â­ï¸ ê°ì •ì„ 6ê°€ì§€ë¡œ ë³€ê²½
EMOTIONS = ["í–‰ë³µ", "ì‚¬ë‘", "ìŠ¬í””", "ë¶„ë…¸", "í˜ë“¦", "ë†€ëŒ"]
TIMES = ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"]
TIME_KEYWORDS = { "ì•„ì¹¨": ["ì•„ì¹¨", "ì˜¤ì „", "ì¶œê·¼", "ì¼ì–´ë‚˜ì„œ"], "ì ì‹¬": ["ì ì‹¬", "ë‚®", "ì ì‹¬ì‹œê°„"], "ì €ë…": ["ì €ë…", "ì˜¤í›„", "í‡´ê·¼", "ë°¤", "ìƒˆë²½", "ìê¸° ì „", "ê¿ˆ"],}

# --- 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
@st.cache_resource
def load_ml_resources():
    try:
        model = joblib.load(MODEL_PATH)
        vectorizer = joblib.load(VECTORIZER_PATH)
        return model, vectorizer
    except FileNotFoundError: return None, None

@st.cache_resource
def get_gsheets_connection():
    try:
        creds_dict = st.secrets["connections"]["gsheets"]
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        credentials = Credentials.from_service_account_info(creds_dict, scopes=scope)
        client = gspread.authorize(credentials)
        return client
    except Exception:
        return None

def analyze_diary_ml(model, vectorizer, text):
    if not model or not vectorizer: return None, None
    sentences = re.split(r'[.?!]', text); sentences = [s.strip() for s in sentences if s.strip()]
    time_scores = { t: {e: 0 for e in EMOTIONS} for t in TIMES }
    analysis_results = []
    for sentence in sentences:
        current_time = "ì €ë…"
        for time_key, keywords in TIME_KEYWORDS.items():
            if any(keyword in sentence for keyword in keywords): current_time = time_key; break
        text_vector = vectorizer.transform([sentence])
        prediction = model.predict(text_vector)[0]
        if prediction in time_scores.get(current_time, {}):
             time_scores[current_time][prediction] += 1
        analysis_results.append({'sentence': sentence, 'predicted_emotion': prediction, 'predicted_time': current_time})
    return time_scores, analysis_results

def recommend(final_emotion):
    # â­ï¸ 6ê°€ì§€ ê°ì •ì— ë§ê²Œ ì¶”ì²œ ëª©ë¡ ì—…ë°ì´íŠ¸
    recommendations = {
        "í–‰ë³µ": {"ì±…": ["ê¸°ë¶„ì„ ê´€ë¦¬í•˜ë©´ ì¸ìƒì´ ê´€ë¦¬ëœë‹¤"], "ìŒì•…": ["ì•…ë®¤ - DINOSAUR"], "ì˜í™”": ["ì›”í„°ì˜ ìƒìƒì€ í˜„ì‹¤ì´ ëœë‹¤"]},
        "ì‚¬ë‘": {"ì±…": ["ì‚¬ë‘ì˜ ê¸°ìˆ "], "ìŒì•…": ["í´í‚´ - ëª¨ë“  ë‚ , ëª¨ë“  ìˆœê°„"], "ì˜í™”": ["ì–´ë°”ì›ƒ íƒ€ì„"]},
        "ìŠ¬í””": {"ì±…": ["ì•„ëª¬ë“œ"], "ìŒì•…": ["ì´ì„ í¬ - ì¸ì—°"], "ì˜í™”": ["ì½”ì½”"]},
        "ë¶„ë…¸": {"ì±…": ["ë¶„ë…¸ì˜ ì‹¬ë¦¬í•™"], "ìŒì•…": ["G-DRAGON - ì‚ë”±í•˜ê²Œ"], "ì˜í™”": ["ì„±ë‚œ ì‚¬ëŒë“¤ (ë“œë¼ë§ˆ)"]},
        "í˜ë“¦": {"ì±…": ["ì£½ê³  ì‹¶ì§€ë§Œ ë–¡ë³¶ì´ëŠ” ë¨¹ê³  ì‹¶ì–´"], "ìŒì•…": ["ì˜¥ìƒë‹¬ë¹› - ìˆ˜ê³ í–ˆì–´, ì˜¤ëŠ˜ë„"], "ì˜í™”": ["ë¦¬í‹€ í¬ë ˆìŠ¤íŠ¸"]},
        "ë†€ëŒ": {"ì±…": ["ë°ë¯¸ì•ˆ"], "ìŒì•…": ["Queen - Bohemian Rhapsody"], "ì˜í™”": ["ìœ ì „"]},
    }
    return recommendations.get(final_emotion, {"ì±…": [], "ìŒì•…": [], "ì˜í™”": []})

def save_feedback_to_gsheets(client, feedback_df):
    try:
        spreadsheet = client.open("diary_app_feedback")
        worksheet = spreadsheet.worksheet("Sheet1")
        existing_data = pd.DataFrame(worksheet.get_all_records())
        feedback_to_save = feedback_df[['text', 'label']]
        updated_df = pd.concat([existing_data, feedback_to_save], ignore_index=True)
        updated_df.drop_duplicates(subset=['text'], keep='last', inplace=True)
        worksheet.clear()
        worksheet.update([updated_df.columns.values.tolist()] + updated_df.values.tolist())
        st.success("ì†Œì¤‘í•œ í”¼ë“œë°±ì´ Google Sheetsì— ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def generate_random_diary():
    morning = ["ì•„ì¹¨ì— ìƒì¾Œí•˜ê²Œ ì¼ì–´ë‚¬ë‹¤.", "ì¶œê·¼ê¸¸ ì§€í•˜ì² ì— ì‚¬ëŒì´ ë„ˆë¬´ ë§ì•„ í˜ë“¤ì—ˆë‹¤."]
    afternoon = ["ì ì‹¬ìœ¼ë¡œ ë§›ìˆëŠ” íŒŒìŠ¤íƒ€ë¥¼ ë¨¹ì–´ì„œ ê¸°ë¶„ì´ ì¢‹ì•˜ë‹¤.", "ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì†Œì‹ì„ ë“£ê³  ë„ˆë¬´ ë†€ëë‹¤."]
    evening = ["í‡´ê·¼í•˜ê³  ìš´ë™ì„ í•˜ë‹ˆ ê°œìš´í–ˆë‹¤.", "ìê¸° ì „ì— ë³¸ ì˜í™”ê°€ ì •ë§ ê°ë™ì ì´ê³  ì‚¬ë‘ìŠ¤ëŸ¬ì› ë‹¤."]
    return f"{random.choice(morning)} {random.choice(afternoon)} {random.choice(evening)}"

def handle_random_click():
    st.session_state.diary_text = generate_random_diary()
    st.session_state.analysis_results = None

def handle_analyze_click(model, vectorizer):
    diary_content = st.session_state.diary_text
    if not diary_content.strip():
        st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    elif model is None or vectorizer is None:
        st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. GitHubì—ì„œ ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner('AIê°€ ì¼ê¸°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            _, results = analyze_diary_ml(model, vectorizer, diary_content)
            st.session_state.analysis_results = results

# --- 3. Streamlit UI êµ¬ì„± ---
st.set_page_config(layout="wide")
st.title("ğŸ“Š í•˜ë£¨ ê°ì • ë¶„ì„ ë¦¬í¬íŠ¸ (v6.3)")

model, vectorizer = load_ml_resources()

if 'diary_text' not in st.session_state: st.session_state.diary_text = "ì˜¤ëŠ˜ ì•„ì¹¨ ê¹œì§ ì„ ë¬¼ì„ ë°›ê³  ë„ˆë¬´ ë†€ëê³  í–‰ë³µí–ˆë‹¤. ì ì‹¬ì—ëŠ” ì¹œêµ¬ì™€ ì‚¬ì†Œí•œ ë‹¤íˆ¼ìœ¼ë¡œ ìŠ¬íì§€ë§Œ, ì €ë…ì— ì—°ì¸ê³¼ ë§›ìˆëŠ” ê²ƒì„ ë¨¹ìœ¼ë©° ì‚¬ë‘ì„ ëŠê¼ˆë‹¤."
if 'analysis_results' not in st.session_state: st.session_state.analysis_results = None

col1, col2 = st.columns([3, 1])
with col1:
    st.text_area("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì‘ì„±í•´ë³´ì„¸ìš”:", key='diary_text', height=250)
with col2:
    st.write(" "); st.write(" ")
    st.button("ğŸ”„ ëœë¤ ì¼ê¸° ìƒì„±", on_click=handle_random_click)
    st.button("ğŸ” ë‚´ í•˜ë£¨ ê°ì • ë¶„ì„í•˜ê¸°", type="primary", on_click=handle_analyze_click, args=(model, vectorizer))

if st.session_state.analysis_results:
    if model is None or vectorizer is None:
        st.error("ëª¨ë¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GitHub ì €ì¥ì†Œì— pkl íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        scores_data, _ = analyze_diary_ml(model, vectorizer, st.session_state.diary_text)
        df_scores = pd.DataFrame(scores_data).T
        if df_scores.sum().sum() > 0:
            st.subheader("ğŸ•’ ì‹œê°„ëŒ€ë³„ ê°ì • ë¶„ì„ ê²°ê³¼")
            final_emotion = df_scores.sum().idxmax()
            res_col1, res_col2 = st.columns([1.2, 1])
            with res_col1:
                fig, ax = plt.subplots(figsize=(8, 5))
                df_scores.plot(kind='bar', stacked=True, ax=ax, width=0.8, colormap='Pastel1', edgecolor='grey')
                ax.set_title("ì‹œê°„ëŒ€ë³„ ê°ì • ë³€í™” ê·¸ë˜í”„", fontsize=16); ax.set_ylabel("ê°ì • ë¬¸ì¥ ìˆ˜", fontsize=12)
                ax.set_xticklabels(df_scores.index, rotation=0, fontsize=12)
                ax.legend(title="ê°ì •", bbox_to_anchor=(1.02, 1), loc='upper left'); plt.tight_layout()
                st.pyplot(fig)
            with res_col2:
                st.dataframe(df_scores.style.format("{:.0f}").background_gradient(cmap='viridis'))
                st.success(f"ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ì¢…í•©í•´ ë³´ë©´, **'{final_emotion}'**ì˜ ê°ì •ì´ ê°€ì¥ ì»¸ë„¤ìš”!")
            st.divider()
            st.subheader(f"'{final_emotion}' ê°ì •ì„ ìœ„í•œ ì˜¤ëŠ˜ì˜ ì¶”ì²œ")
            recs = recommend(final_emotion)
            rec_col1, rec_col2, rec_col3 = st.columns(3)
            with rec_col1:
                st.write("ğŸ“š **ì´ëŸ° ì±…ì€ ì–´ë•Œìš”?**")
                for item in recs['ì±…']: st.write(f"- {item}")
            with rec_col2:
                st.write("ğŸµ **ì´ëŸ° ìŒì•…ë„ ë“¤ì–´ë³´ì„¸ìš”?**")
                for item in recs['ìŒì•…']: st.write(f"- {item}")
            with rec_col3:
                st.write("ğŸ¬ **ì´ëŸ° ì˜í™”/ë“œë¼ë§ˆë„ ì¶”ì²œí•´ìš”!**")
                for item in recs['ì˜í™”']: st.write(f"- {item}")
            st.divider()
            st.subheader("ğŸ” ë¶„ì„ ê²°ê³¼ í”¼ë“œë°±")
            feedback_data = []
            for i, result in enumerate(st.session_state.analysis_results):
                st.markdown(f"> {result['sentence']}")
                cols = st.columns([1, 1])
                with cols[0]:
                    correct_time = st.radio("ì´ ë¬¸ì¥ì˜ ì‹œê°„ëŒ€ëŠ”?", TIMES, index=TIMES.index(result['predicted_time']), key=f"time_{i}", horizontal=True)
                with cols[1]:
                    # â­ï¸ 6ê°€ì§€ ê°ì • ì¤‘ ì—†ëŠ” ê°ì •ì´ ì˜ˆì¸¡ë˜ì—ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬
                    try:
                        emotion_index = EMOTIONS.index(result['predicted_emotion'])
                    except ValueError:
                        emotion_index = 0 # ì—†ëŠ” ê°ì •ì´ë©´ ì²« ë²ˆì§¸ ê°ì •(í–‰ë³µ)ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
                    correct_emotion = st.selectbox("ì´ ë¬¸ì¥ì˜ ì§„ì§œ ê°ì •ì€?", EMOTIONS, index=emotion_index, key=f"emotion_{i}")
                feedback_data.append({'text': result['sentence'], 'label': correct_emotion, 'time': correct_time})
                st.write("---")
            if st.button("í”¼ë“œë°± ì œì¶œí•˜ê¸°"):
                client = get_gsheets_connection()
                if client:
                    changed_feedback = []
                    for i, row in enumerate(pd.DataFrame(feedback_data).to_dict('records')):
                        original = st.session_state.analysis_results[i]
                        if row['label'] != original['predicted_emotion'] or row['time'] != original['predicted_time']:
                            changed_feedback.append({'text': row['text'], 'label': row['label']})
                    if changed_feedback:
                        final_feedback_df = pd.DataFrame(changed_feedback)
                        save_feedback_to_gsheets(client, final_feedback_df)
                        st.session_state.analysis_results = None; st.rerun()
                    else: st.info("ìˆ˜ì •ëœ ë‚´ìš©ì´ ì—†ë„¤ìš”. AIê°€ ì˜ ë§ì·„ë‚˜ ë³´ë„¤ìš”! ğŸ˜„")
                else:
                    st.error("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

with st.expander("í”¼ë“œë°± ì €ì¥ í˜„í™© ë³´ê¸° (Google Sheets)"):
    client = get_gsheets_connection()
    if client:
        try:
            spreadsheet = client.open("diary_app_feedback")
            worksheet = spreadsheet.worksheet("Sheet1")
            df = pd.DataFrame(worksheet.get_all_records())
            st.dataframe(df)
            st.info(f"í˜„ì¬ ì´ **{len(df)}ê°œ**ì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        except gspread.exceptions.SpreadsheetNotFound:
            st.error("Google Sheetsì—ì„œ 'diary_app_feedback' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except gspread.exceptions.WorksheetNotFound:
            st.error("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì—ì„œ 'Sheet1' ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œíŠ¸ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.error("Google Sheetsì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        st.error("1. Streamlit Secretsì— ì¸ì¦ ì •ë³´ê°€ ì •í™•í•œê°€ìš”?")
        st.error("2. Google Sheets íŒŒì¼ì´ ì„œë¹„ìŠ¤ ê³„ì •ì— 'í¸ì§‘ì'ë¡œ ê³µìœ ë˜ì—ˆë‚˜ìš”?")